{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc253cb",
   "metadata": {},
   "source": [
    "## Code for supplementary figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c512825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using kernel .mne-python (Python 3.10.10)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.stats import (\n",
    "    ttest_ind, bootstrap\n",
    ")\n",
    "from scipy import io\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import mne\n",
    "from mne.viz.topomap import _prepare_topomap_plot, _make_head_outlines\n",
    "\n",
    "import h5io\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from meeglet import define_frequencies\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3524832d",
   "metadata": {},
   "source": [
    " Create adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93943a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = (\n",
    "    str(sample_data_folder) + \"/MEG/sample/sample_audvis_filt-0-40_raw.fif\"\n",
    ")\n",
    "raw_for_adjacency = mne.io.read_raw_fif(sample_data_raw_file)\n",
    "meg_indices = raw_for_adjacency.pick_types(meg='mag')\n",
    "adj_matrix = mne.channels.find_ch_adjacency(raw_for_adjacency.info, 'mag')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "foi = define_frequencies(foi_start=1, foi_end=64, bw_oct=0.35, delta_oct=0.05)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f99f8c",
   "metadata": {},
   "source": [
    "### IMPORT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af66d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_CBU = h5io.read_hdf5('./phd2022/BIOFIND/cosmeeg_CBU_2023-06-22_10-06.h5')\n",
    "features_CTB1 = h5io.read_hdf5('./phd2022/BIOFIND/cosmeeg_CTB_2023-06-22_10-46.h5')\n",
    "features_CTB2 = h5io.read_hdf5('./phd2022/BIOFIND/cosmeeg_CTB_2023-06-23_11-04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = features_CTB1 | features_CTB2 | features_CBU #merge 3 hdf5 files (key: patient, value : tuple cov, pow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all.keys()\n",
    "features_all['Sub0014'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow = np.array([features_all[subject][1] for subject in features_all]) # 0 cov, 1 pow, 2 csd\n",
    "pow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634aa6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "participants_fname = '/Users/sinead/github/phd2022/BIOFIND/participants.tsv'\n",
    "subject_df = pd.read_csv(participants_fname, delimiter='\\t')\n",
    "subject_df['participant_id'] = subject_df['participant_id'].str.replace('sub-', '')\n",
    "subject_df = subject_df.set_index('participant_id') # creates index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07ba49",
   "metadata": {},
   "source": [
    "### Build subject groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61563292",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mmse = subject_df['MMSE'].mean()\n",
    "subject_df['MMSE'] = subject_df['MMSE'].fillna(mean_mmse)\n",
    "mean_edu = subject_df['Edu_years'].mean()\n",
    "subject_df['Edu_years'] = subject_df['Edu_years'].fillna(mean_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5bda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df = subject_df.loc[features_all.keys()] # dataframe in correct order\n",
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa696e97",
   "metadata": {},
   "source": [
    "# Analysis PSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023929df",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mmse = list(subject_df['MMSE'])\n",
    "feature_control = [ 1 if is_control else 0 for is_control in subject_df['group'] == 'control']\n",
    "feature_converter = subject_df['Converters'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds = np.array([features_all[subject][1] for subject in features_all]) # 0 cov, 1 pow, 2 csd\n",
    "psds = 10*np.log10(psds) #dB\n",
    "psds_mean_chan = np.mean(psds, 1) #mean over channels\n",
    "psds_mean_chan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72dd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del features_all, features_CBU, features_CTB1, features_CTB2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31fde04",
   "metadata": {},
   "source": [
    "## ADJUST FOR CONVERTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600dde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df_adjust3 = subject_df.copy()\n",
    "subject_df_adjust3['Converters'] = subject_df_adjust3['Converters'].fillna(-1)\n",
    "subject_df_adjust3.loc[subject_df_adjust3['Converters'] >= 0].index.to_numpy()\n",
    "converters_idx = subject_df_adjust3['Converters'] >= 0\n",
    "psds_mean_chan[converters_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25575e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust on all confounds: site, sex, age, Recording_time, Edu_years, Move1, Move2, Pre_task\n",
    "subject_df_adjust = subject_df[['MMSE']]\n",
    "\n",
    "z = subject_df_adjust.to_numpy()[converters_idx]\n",
    "\n",
    "psds_clean_converter = np.zeros_like(psds[converters_idx])\n",
    "\n",
    "for chan in range(psds.shape[1]):\n",
    "    for freq in range(psds.shape[2]):\n",
    "\n",
    "        lm = LinearRegression() #initialize the model\n",
    "        X = psds[converters_idx, chan, freq]\n",
    "\n",
    "        lm = lm.fit(z, X) \n",
    "        X_clean = X - lm.predict(z) + lm.intercept_\n",
    "        \n",
    "        psds_clean_converter[:, chan, freq] = X_clean\n",
    "\n",
    "psds_clean_mean_converter = np.mean(psds_clean_converter, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_clean_mean_converter.shape\n",
    "psds_clean_converter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf82ea",
   "metadata": {},
   "source": [
    "## PLOT ADJUSTED PSD CONVERTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92cad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 11\n",
    "fig, axes = plt.subplots(1,1, figsize=[3.6,1.4],sharey=True)\n",
    "psd_mean_converter = np.mean(psds_clean_mean_converter[np.array(feature_converter[feature_converter >= 0]) == 1],0)\n",
    "psd_mean_non_converter = np.mean(psds_clean_mean_converter[np.array(feature_converter[feature_converter >= 0]) == 0],0)\n",
    "\n",
    "plt.plot(foi, psd_mean_converter, label='AD progression', linewidth = 2.2)\n",
    "plt.plot(foi, psd_mean_non_converter, label = 'Stable MCI', linewidth = 2.2)\n",
    "\n",
    "legend = plt.legend(loc='upper right', bbox_to_anchor=(0.6, 0.43))\n",
    "frame = legend.get_frame()\n",
    "frame.set_linewidth(0)  \n",
    "plt.title('Average power spectra', fontsize = 11, y=1)\n",
    "plt.xlabel('Frequencies (Hz)')\n",
    "plt.ylabel('Power (dB)')\n",
    "plt.ylim(-280,-260)\n",
    "plt.xscale('log', base =2)\n",
    "plt.xticks([1,2,4,8,16,32,64],labels = [1,2,4,8,16,32,64])\n",
    "#plt.xticks(plt.xticks()[0][2:-2], labels = [1,2,4,8,16,32,64])\n",
    "sns.despine(offset=10, trim=True);[converters_idx]\n",
    "#plt.show()\n",
    "plt.savefig('./figures/average_meg_power_mmse.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d94df5",
   "metadata": {},
   "source": [
    "## T-test to compare mean PSD between groups (converters vs non converters) at definite frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e11bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T test to compare mean psd between groups at definite frequencies (2, 4, 8, 16, 32Hz)\n",
    "psds_mean_channels_converters_all = np.mean((psds_clean_converter[:,:,20:120:20]),1)\n",
    "psds_mean_channels_converters = psds_mean_channels_converters_all[np.array(feature_converter[converters_idx]) == 1]\n",
    "psds_mean_channels_nonconverters = psds_mean_channels_converters_all[np.array(feature_converter[converters_idx]) == 0]\n",
    "#psds_mean_channels_converters.shape\n",
    "t_statistic, p_value_conv = ttest_ind(psds_mean_channels_converters, psds_mean_channels_nonconverters, axis=0, equal_var=False)\n",
    "print(p_value_conv*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef859799",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdsT = psds_clean_converter.transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_mean_channels_converters_all.shape\n",
    "np.mean(psdsT[feature_converter[converters_idx] == 0],2).shape\n",
    "\n",
    "psds_clean_mean_converter[np.array(feature_converter[feature_converter >= 0]) == 1].shape\n",
    "psds_clean_mean_converter[np.array(feature_converter[feature_converter >= 0]) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0597105",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdsT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca0991",
   "metadata": {},
   "source": [
    "## Permutation F-test on sensor data averaged over all sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ac9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_condition_1 = psds_clean_mean_converter[np.array(feature_converter[feature_converter >= 0]) == 0]\n",
    "data_condition_2 = psds_clean_mean_converter[np.array(feature_converter[feature_converter >= 0]) == 1]\n",
    "\n",
    "# Prepare your data for cluster-based permutation test\n",
    "X = [data_condition_1, data_condition_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc9385",
   "metadata": {},
   "source": [
    "## TFCE F-test method to compare averaged metrics between groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363873b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_obs, clusters, cluster_p_values, H0 = mne.stats.permutation_cluster_test(\n",
    "    [data_condition_2, data_condition_1], \n",
    "    threshold = dict(start=0, step=0.2), \n",
    "    n_jobs=None, \n",
    "    n_permutations=10000, \n",
    "    tail=0, out_type=\"mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4368586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f625e9b9",
   "metadata": {},
   "source": [
    "### Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c52fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(23)\n",
    "\n",
    "def my_statistic(sample1, sample2, axis=0):\n",
    "    statistic = np.mean(sample1) - np.mean(sample2)\n",
    "    return statistic\n",
    "\n",
    "condition1 = data_condition_1\n",
    "condition2 = data_condition_2\n",
    "\n",
    "results = list()\n",
    "\n",
    "for ii in range(condition2.shape[1]):\n",
    "    data = (condition2[:, ii], condition1[:, ii])\n",
    "    res = bootstrap(data, my_statistic, method='basic', random_state=rng, vectorized=False)\n",
    "    results.append(res)    \n",
    "\n",
    "conf_ints = np.array([tuple(res.confidence_interval) for res in results])\n",
    "conf_ints.shape\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# mean PSD difference\n",
    "mean_difference = condition2.mean(axis=0) - condition1.mean(axis=0)\n",
    "\n",
    "# IC95 for the difference\n",
    "upper_bound = conf_ints[:,1]\n",
    "lower_bound = conf_ints[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=[3.6,1.4], sharey=True)\n",
    "ax.set_title('PSD difference between groups', fontsize = 11.5, y=1.05)\n",
    "ax.set_xscale('log', base=2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "xticks = [1, 2, 4, 8, 16, 32, 64]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks)\n",
    "#ax.set_ylim(-1, 1.7)\n",
    "ax.set_xlim(1, 64)\n",
    "ax.axhline(0, color='black', linestyle= \"--\")\n",
    "sns.despine(offset=5, trim=False)\n",
    "\n",
    "# Plot the mean difference\n",
    "line = ax.plot(\n",
    "    foi,\n",
    "    mean_difference,\n",
    "    label=\"Mean Difference\"\n",
    ")\n",
    "\n",
    "# Fill the area between upper and lower CI bounds\n",
    "ax.fill_between(foi,upper_bound, lower_bound, alpha=0.5, label=\"95% CI\")\n",
    "\n",
    "ax.set_ylabel(\"PSD difference (dB)\")\n",
    "ax.set_xlabel(\"Frequencies (Hz)\")\n",
    "#legend = plt.legend(loc='upper right', bbox_to_anchor=(1.2, 0.6))\n",
    "#frame = legend.get_frame()\n",
    "#frame.set_linewidth(0) \n",
    "#ax.legend()\n",
    "\n",
    "plt.savefig('./figures/figure1b_mmse.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `foi`, `T_obs`, and `cluster_p_values` are defined\n",
    "mask = cluster_p_values <= 0.10\n",
    "\n",
    "plt.rcParams['font.size'] = 11\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=[3.6, 1.4], sharey=True)\n",
    "ax2.set_title('Permutation F-test on mean PSD', fontsize = 11.5, y=1.05)\n",
    "\n",
    "# Plot the main black line\n",
    "hf, = ax2.plot(foi, T_obs, \"black\")\n",
    "\n",
    "# Find contiguous regions of significant frequencies\n",
    "inside_cluster = False\n",
    "fill_plotted = False  # Flag to track if the green fill has already been labeled\n",
    "\n",
    "for i in range(len(foi)):\n",
    "    if mask[i] and not inside_cluster:\n",
    "        start_idx = i\n",
    "        inside_cluster = True\n",
    "    elif not mask[i] and inside_cluster:\n",
    "        end_idx = i\n",
    "        # Fill between for this cluster region\n",
    "        if not fill_plotted:\n",
    "            ax2.fill_between(foi[start_idx:end_idx], y1=T_obs[start_idx:end_idx], y2=0, \n",
    "                             color=\"green\", label='cluster P < 0.10', alpha=0.3)\n",
    "            fill_plotted = True  # Set flag to True so that the label is only used once\n",
    "        else:\n",
    "            ax2.fill_between(foi[start_idx:end_idx], y1=T_obs[start_idx:end_idx], y2=0, \n",
    "                             color=\"green\", alpha=0.3)\n",
    "        inside_cluster = False\n",
    "# If a cluster goes till the end of the data\n",
    "if inside_cluster:\n",
    "    if not fill_plotted:\n",
    "        ax2.fill_between(foi[start_idx:], y1=T_obs[start_idx:], y2=0, color=\"green\", alpha=0.3, label='P < 0.10')\n",
    "    else:\n",
    "        ax2.fill_between(foi[start_idx:], y1=T_obs[start_idx:], y2=0, color=\"green\", alpha=0.3)\n",
    "\n",
    "# Set axes labels and scales\n",
    "ax2.set_xlabel(\"Frequencies (Hz)\")\n",
    "ax2.set_ylabel(\"F-values\")\n",
    "ax2.set_xscale('log', base=2)\n",
    "xticks = [1, 2, 4, 8, 16, 32, 64]\n",
    "ax2.set_xticks(xticks)\n",
    "ax2.set_xlim(1, 64)\n",
    "ax2.set_ylim(0,2)\n",
    "ax2.set_xticklabels(xticks)\n",
    "\n",
    "# Customize appearance and remove unnecessary spines\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "sns.despine(offset=5, trim=False)\n",
    "\n",
    "# Add the legend\n",
    "ax2.legend(loc='upper right', bbox_to_anchor=(0.58, 0.6), ncol=2, fontsize=10, frameon=False)\n",
    "\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('./figures/figure1c_mmse_p<0.1.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6537214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(foi[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bf9af",
   "metadata": {},
   "source": [
    "### CLUSTER BASED PERMUTATION TEST TO COMPARE TOPOMAPS BETWEEN GROUPS (keeping spatial info on 102 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_converters = psds_clean_mean_converter[feature_converter[converters_idx] == 1] # psd array adjusted for converters\n",
    "psds_nonconverters = psds_clean_mean_converter[feature_converter[converters_idx] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_clean_mean_converter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdsT = psds_clean_converter.transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "psdsT[feature_converter[converters_idx] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster permutation test with TFCE keeping channel info and frequencies info\n",
    "F, c, alpha, h = mne.stats.spatio_temporal_cluster_test(\n",
    "    [psdsT[feature_converter[converters_idx] == 0],\n",
    "     psdsT[feature_converter[converters_idx] == 1]],\n",
    "    threshold=dict(start=0, step=0.2), n_jobs=4,\n",
    "    n_permutations=10000, tail=0,\n",
    "    adjacency=adj_matrix)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f71cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c has shape 29*102=2958 (tuple : (freq, chan)), each tuple will be called cl\n",
    "# alpha has shape 29*102=2958,containing pvalues\n",
    "p_clust = np.zeros((psdsT.shape[1], psdsT.shape[2])) # init p_clust, shape freq, channels\n",
    "for cl, p in zip(c, alpha): # fills in p_clust array \n",
    "    p_clust[cl]=-np.log10(p)\n",
    "p_clust.shape\n",
    "mask = np.ones_like(p_clust, dtype = bool)\n",
    "mask[p_clust<1.3] = False\n",
    "# will enable to create topomaps of p values for each frequency for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa339580",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(mask.sum(axis=1)>3)[0]  # freqs for significant clusters\n",
    "#foi[idx]\n",
    "print(foi[idx[::2]])\n",
    "#foi[104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_converters = psds_clean_converter[feature_converter[converters_idx] == 1]\n",
    "psds_nonconverters = psds_clean_converter[feature_converter[converters_idx] == 0]\n",
    "psds_converters_mean = np.mean(psds_converters, 0)\n",
    "psds_nonconverters_mean = np.mean(psds_nonconverters, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f09d5e",
   "metadata": {},
   "source": [
    "## PLOT TOPOMAPS FOR CONVERTERS VS NON CONVERTERS DIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e847e",
   "metadata": {},
   "source": [
    "## Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topoplot(    \n",
    "    data,  # 1D array or list with values corresponding to the channels in channel_names\n",
    "    channel_names, # list of channel names, e.g. [\"Fp1\", \"Fp2\", ...]\n",
    "    info,  \n",
    "    montage = \"standard_1020\",\n",
    "    cmap='RdBu_r',\n",
    "    scale_limits=(None, None),  # useful to plot several topographies on the same scale\n",
    "    size=1,  # size of the topoplot\n",
    "    axes=None,\n",
    "    mask=None,\n",
    "):\n",
    "    assert len(data) == len(channel_names)\n",
    "\n",
    "    _, pos, _, _, ch_type, sphere_, clip_origin = _prepare_topomap_plot(\n",
    "        info,\n",
    "        \"mag\",\n",
    "        sphere=(0, 0.023, 0.021, 0.1)\n",
    "    )\n",
    "    \n",
    "    outlines_ = _make_head_outlines(sphere_, pos, 'head', clip_origin)\n",
    "    \n",
    "    im, cn = mne.viz.plot_topomap(\n",
    "        data=data, \n",
    "        pos=pos, \n",
    "        axes=axes,\n",
    "        vlim = scale_limits,\n",
    "        cmap=cmap,\n",
    "        outlines=outlines_,\n",
    "        image_interp='cubic',\n",
    "        size=size,\n",
    "        mask=mask,\n",
    "        show=False,\n",
    "    )\n",
    "\n",
    "    return im, cn\n",
    "\n",
    "def plot_topoplot_grid(\n",
    "    data, # data[i][j] contains a 1D list or array with data for the topo plot in row i and col j\n",
    "    info, \n",
    "    row_labels,  # list of row labels that describe the rows in data, e.g. [\"Condition 1\", \"Condition 2\"]\n",
    "    col_labels,  # list of col labels that describe the cols in data, e.g. [\"Alpha\" ,\"Beta\", \"Gamma\"]\n",
    "    channel_names,  # channel labels in corresponding order to the 1D lists or arrays in data\n",
    "    cbar_mode=\"single\",  # \"single\" for shared scale, \"each\" for individual scales\n",
    "    cbar_label=r\"$10\\times\\log_{10}fT^2/Hz$[dB]\",  # label for the color bar,\n",
    "    #cbar_label=r\"dB\",\n",
    "    cmap='RdBu_r',\n",
    "    scale_limits=(None, None),\n",
    "    mask=None,\n",
    "):\n",
    "    # Figure Grid Params\n",
    "    x_label_size=12\n",
    "    y_label_size=12\n",
    "    x_label_pad=10\n",
    "    y_label_pad=10\n",
    "    \n",
    "    cbar_fmt='%3.2f'\n",
    "    cbar_size=\"5%\"\n",
    "    cbar_pad=0.1 if cbar_mode == \"each\" else 0.8\n",
    "    axes_pad=(0.9 if cbar_mode == \"each\" else 0.4 , 0.4)\n",
    "    clabel_size=10\n",
    "    fig_size=(12, 4)\n",
    "    rect=(0.05, 0.05, 0.90, 0.95)\n",
    "\n",
    "    nrows = len(data)\n",
    "    ncols = len(data[0])\n",
    "\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    grid = ImageGrid(\n",
    "        fig, rect,\n",
    "        nrows_ncols=(nrows, ncols),\n",
    "        axes_pad=axes_pad, share_all=True, cbar_location=\"right\",\n",
    "        cbar_mode=cbar_mode, cbar_size=cbar_size, cbar_pad=cbar_pad,\n",
    "    )\n",
    "\n",
    "    \n",
    "    if cbar_mode == \"single\" and scale_limits == (None, None):\n",
    "        scale_limits = np.array(data).min(), np.array(data).max()\n",
    "    elif cbar_mode == \"each\" and scale_limits == \"columns\":\n",
    "        mins = np.min(np.hstack(data), axis=1)\n",
    "        maxs = np.max(np.hstack(data), axis=1)\n",
    " \n",
    "    scale_limits_ = scale_limits\n",
    "    axes = grid.axes_row\n",
    "    for row, row_label in enumerate(row_labels):\n",
    "        for col, col_label in enumerate(col_labels):\n",
    "            ax = axes[row][col]\n",
    "            if cbar_mode == \"each\" and scale_limits == \"columns\":\n",
    "                scale_limits_ = [mins[col], maxs[col]]\n",
    "            im, _ = topoplot(data[row][col], channel_names, info, scale_limits=scale_limits_,\n",
    "                             axes=ax,\n",
    "                             cmap=cmap,\n",
    "                             mask= None if mask is None else mask[row][col])\n",
    "\n",
    "            ax.set_xlabel(col_label, fontsize=x_label_size, labelpad=x_label_pad)\n",
    "            ax.set_ylabel(row_label, fontsize=y_label_size, labelpad=y_label_pad)\n",
    "\n",
    "            cbar = ax.cax.colorbar(im)\n",
    "            cbar.ax.set_ylabel(cbar_label, fontsize=clabel_size)\n",
    "            ax.cax.toggle_label(True)\n",
    "     \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff744c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(c):\n",
    "    this_min, this_max = np.min(c), np.max(c)\n",
    "    my_max = max(abs(this_min), abs(this_max))\n",
    "    return my_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = np.squeeze(np.array([psds_converters_mean - psds_nonconverters_mean]))\n",
    "\n",
    "data_diff = [\n",
    "    [difference[:, ix] for ix in idx[::3][:6]],\n",
    "]\n",
    "mask_grid = [\n",
    "    [mask.T[:, ix] for ix in idx[::3][:6]],\n",
    "]\n",
    "row_labels = [\"Difference\"]\n",
    "col_labels = [f\"{f:0.1f} Hz\" for f in foi[idx[::3][:6]]]\n",
    "channel_names = raw_for_adjacency.info.ch_names\n",
    "\n",
    "fig = plot_topoplot_grid(data_diff, raw_for_adjacency.info, row_labels, col_labels, channel_names, scale_limits = [lambda x: -min_max(x), min_max],\n",
    "                         cbar_mode=\"single\", mask=mask_grid,\n",
    "                         );\n",
    "fig.set_size_inches(10, 2)\n",
    "plt.savefig('./figures/figure1_topoplot_diff_top_mmse.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = np.squeeze(np.array([psds_converters_mean - psds_nonconverters_mean]))\n",
    "\n",
    "data_diff = [\n",
    "    [difference[:, ix] for ix in idx[::3][5:]],\n",
    "]\n",
    "mask_grid = [\n",
    "    [mask.T[:, ix] for ix in idx[::3][5:]],\n",
    "]\n",
    "row_labels = [\"Difference\"]\n",
    "col_labels = [f\"{f:0.1f} Hz\" for f in foi[idx[::3][5:]]]\n",
    "channel_names = raw_for_adjacency.info.ch_names\n",
    "\n",
    "fig = plot_topoplot_grid(data_diff, raw_for_adjacency.info, row_labels, col_labels, channel_names, scale_limits = [lambda x: -min_max(x), min_max],\n",
    "                         cbar_mode=\"single\", mask=mask_grid,\n",
    "                         );\n",
    "fig.set_size_inches(10, 2)\n",
    "plt.savefig('./figures/figure1_topoplot_diff_bot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05667566",
   "metadata": {},
   "source": [
    "## EXPORT CLUSTER MMSE ADJUSTED PSD VALUES FOR R STUDIO ANALYSIS (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_15_5_post = np.where(mask[79,:])[0]\n",
    "idx_16_post = np.where(mask[80,:])[0]\n",
    "idx_18_4_post = np.where(mask[84,:])[0]\n",
    "idx_19_post = np.where(mask[85,:])[0]\n",
    "idx_22_6_post = np.where(mask[90,:])[0]\n",
    "idx_23_post = np.where(mask[91,:])[0]\n",
    "idx_27_9_post = np.where(mask[96,:])[0]\n",
    "idx_28_post = np.where(mask[97,:])[0]\n",
    "idx_34_3_post = np.where(mask[102,:])[0]\n",
    "idx_35_post = np.where(mask[103,:])[0]\n",
    "idx_36_8_post = np.where(mask[104,:])[0]\n",
    "idx_38_post = np.where(mask[105,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9af8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_clean_converter[np.array(feature_converter[feature_converter >= 0]) == 0].shape\n",
    "np.array([ is_converter for is_converter in feature_converter[feature_converter >= 0]]).shape\n",
    "i = 0\n",
    "j = 0\n",
    "megf15_5_post_adjust = np.zeros((323))\n",
    "megf16_post_adjust = np.zeros((323))\n",
    "megf18_4_post_adjust = np.zeros((323))\n",
    "megf19_post_adjust = np.zeros((323))\n",
    "megf22_6_post_adjust = np.zeros((323))\n",
    "megf23_post_adjust = np.zeros((323))\n",
    "megf27_9_post_adjust = np.zeros((323))\n",
    "megf28_post_adjust = np.zeros((323))\n",
    "megf34_3_post_adjust = np.zeros((323))\n",
    "megf35_5_post_adjust = np.zeros((323))\n",
    "megf36_8_post_adjust = np.zeros((323))\n",
    "megf38_post_adjust = np.zeros((323))\n",
    "\n",
    "for index, row in subject_df.iterrows():\n",
    "    if feature_converter[index] >= 0:\n",
    "        megf15_5_post_adjust[j] = np.mean(psds_clean_converter[i,idx_15_5_post,79],0)\n",
    "        megf16_post_adjust[j] = np.mean(psds_clean_converter[i,idx_16_post,80],0)\n",
    "        megf18_4_post_adjust[j] = np.mean(psds_clean_converter[i,idx_18_4_post,84],0)\n",
    "        megf19_post_adjust[j] = np.mean(psds_clean_converter[i,idx_19_post,85],0)\n",
    "        megf22_6_post_adjust[j] = np.mean(psds_clean_converter[i,idx_22_6_post,90],0)\n",
    "        megf23_post_adjust[j] = np.mean(psds_clean_converter[i,idx_23_post,91],0)\n",
    "        megf27_9_post_adjust[j] = np.mean(psds_clean_converter[i,idx_27_9_post,96],0)\n",
    "        megf28_post_adjust[j] = np.mean(psds_clean_converter[i,idx_28_post,97],0)\n",
    "        megf34_3_post_adjust[j] = np.mean(psds_clean_converter[i,idx_34_3_post,102],0)\n",
    "        megf35_5_post_adjust[j] = np.mean(psds_clean_converter[i,idx_35_post,103],0)\n",
    "        megf36_8_post_adjust[j] = np.mean(psds_clean_converter[i,idx_36_8_post,104],0)\n",
    "        megf38_post_adjust[j] = np.mean(psds_clean_converter[i,idx_38_post,105],0)\n",
    "\n",
    "        i = i + 1\n",
    "    else:\n",
    "        megf15_5_post_adjust[j] = None\n",
    "        megf16_post_adjust[j] = None\n",
    "        megf18_4_post_adjust[j] = None\n",
    "        megf19_post_adjust[j] = None\n",
    "        megf22_6_post_adjust[j] = None\n",
    "        megf23_post_adjust[j] = None\n",
    "        megf27_9_post_adjust[j] = None\n",
    "        megf28_post_adjust[j] = None\n",
    "        megf34_3_post_adjust[j] = None\n",
    "        megf35_5_post_adjust[j] = None\n",
    "        megf36_8_post_adjust[j] = None\n",
    "        megf38_post_adjust[j] = None\n",
    "    j = j + 1\n",
    "#megf15_5_post_adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6452073",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df_Rstudio = subject_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df_Rstudio['megf15_5_post_adjust']= megf15_5_post_adjust\n",
    "subject_df_Rstudio['megf16_post_adjust']=megf16_post_adjust\n",
    "subject_df_Rstudio['megf18_4_post_adjust']= megf18_4_post_adjust\n",
    "subject_df_Rstudio['megf19_post_adjust']= megf19_post_adjust\n",
    "subject_df_Rstudio['megf22_6_post_adjust']= megf22_6_post_adjust\n",
    "subject_df_Rstudio['megf23_post_adjust']= megf23_post_adjust\n",
    "subject_df_Rstudio['megf27_9_post_adjust']= megf27_9_post_adjust\n",
    "subject_df_Rstudio['megf28_post_adjust']= megf28_post_adjust\n",
    "subject_df_Rstudio['megf34_3_post_adjust']= megf34_3_post_adjust\n",
    "subject_df_Rstudio['megf35_5_post_adjust']= megf35_5_post_adjust\n",
    "subject_df_Rstudio['megf36_8_post_adjust']= megf36_8_post_adjust\n",
    "subject_df_Rstudio['megf38_post_adjust']= megf38_post_adjust\n",
    "\n",
    "subject_df_Rstudio.to_csv('./stats_model_data_adj_R5.csv') # export PSD cluster MMSE adjusted values for R studio analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca1fb4",
   "metadata": {},
   "source": [
    "## EXPORT PSD VALUES MMSE ADJUSTED AVERAGE OVER ALL SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed111d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "psds_clean_converter[np.array(feature_converter[feature_converter >= 0]) == 0].shape\n",
    "np.array([ is_converter for is_converter in feature_converter[feature_converter >= 0]]).shape\n",
    "i = 0\n",
    "j = 0\n",
    "megf15_5_average_adjust = np.zeros((323))\n",
    "megf16_average_adjust = np.zeros((323))\n",
    "megf18_4_average_adjust = np.zeros((323))\n",
    "megf19_average_adjust = np.zeros((323))\n",
    "megf22_6_average_adjust = np.zeros((323))\n",
    "megf23_average_adjust = np.zeros((323))\n",
    "megf27_9_average_adjust = np.zeros((323))\n",
    "megf28_average_adjust = np.zeros((323))\n",
    "megf34_3_average_adjust = np.zeros((323))\n",
    "megf35_5_average_adjust = np.zeros((323))\n",
    "megf36_8_average_adjust = np.zeros((323))\n",
    "megf38_average_adjust = np.zeros((323))\n",
    "\n",
    "for index, row in subject_df.iterrows():\n",
    "    if feature_converter[index] >= 0:\n",
    "        megf15_5_average_adjust[j] = np.mean(psds_clean_converter[i,:,79],0)\n",
    "        megf16_average_adjust[j] = np.mean(psds_clean_converter[i,:,80],0)\n",
    "        megf18_4_average_adjust[j] = np.mean(psds_clean_converter[i,:,84],0)\n",
    "        megf19_average_adjust[j] = np.mean(psds_clean_converter[i,:,85],0)\n",
    "        megf22_6_average_adjust[j] = np.mean(psds_clean_converter[i,:,90],0)\n",
    "        megf23_average_adjust[j] = np.mean(psds_clean_converter[i,:,91],0)\n",
    "        megf27_9_average_adjust[j] = np.mean(psds_clean_converter[i,:,96],0)\n",
    "        megf28_average_adjust[j] = np.mean(psds_clean_converter[i,:,97],0)\n",
    "        megf34_3_average_adjust[j] = np.mean(psds_clean_converter[i,:,102],0)\n",
    "        megf35_5_average_adjust[j] = np.mean(psds_clean_converter[i,:,103],0)\n",
    "        megf36_8_average_adjust[j] = np.mean(psds_clean_converter[i,:,104],0)\n",
    "        megf38_average_adjust[j] = np.mean(psds_clean_converter[i,:,105],0)\n",
    "\n",
    "        i = i + 1\n",
    "    else:\n",
    "        megf15_5_average_adjust[j] = None\n",
    "        megf16_average_adjust[j] = None\n",
    "        megf18_4_average_adjust[j] = None\n",
    "        megf19_average_adjust[j] = None\n",
    "        megf22_6_average_adjust[j] = None\n",
    "        megf23_average_adjust[j] = None\n",
    "        megf27_9_average_adjust[j] = None\n",
    "        megf28_average_adjust[j] = None\n",
    "        megf34_3_average_adjust[j] = None\n",
    "        megf35_5_average_adjust[j] = None\n",
    "        megf36_8_average_adjust[j] = None\n",
    "        megf38_average_adjust[j] = None\n",
    "    j = j + 1\n",
    "#megf15_5_post_adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9221ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df_Rstudio = subject_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df_Rstudio['megf15_5_average_adjust']= megf15_5_average_adjust\n",
    "subject_df_Rstudio['megf16_average_adjust']=megf16_average_adjust\n",
    "subject_df_Rstudio['megf18_4_average_adjust']= megf18_4_average_adjust\n",
    "subject_df_Rstudio['megf19_average_adjust']= megf19_average_adjust\n",
    "subject_df_Rstudio['megf22_6_average_adjust']= megf22_6_average_adjust\n",
    "subject_df_Rstudio['megf23_average_adjust']= megf23_average_adjust\n",
    "subject_df_Rstudio['megf27_9_average_adjust']= megf27_9_average_adjust\n",
    "subject_df_Rstudio['megf28_average_adjust']= megf28_average_adjust\n",
    "subject_df_Rstudio['megf34_3_average_adjust']= megf34_3_average_adjust\n",
    "subject_df_Rstudio['megf35_5_average_adjust']= megf35_5_average_adjust\n",
    "subject_df_Rstudio['megf36_8_average_adjust']= megf36_8_average_adjust\n",
    "subject_df_Rstudio['megf38_average_adjust']= megf38_average_adjust\n",
    "\n",
    "subject_df_Rstudio.to_csv('./stats_model_data_adj_R6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08942781",
   "metadata": {},
   "source": [
    "## EXPORT PSD NON MMSE ADJUSTED VALUES AVERAGE OVER ALL SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7176ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df_Rstudio['megf14']= psds_mean_chan[:,76]\n",
    "subject_df_Rstudio['megf15']= psds_mean_chan[:,78]\n",
    "subject_df_Rstudio['megf16']= psds_mean_chan[:,80]\n",
    "subject_df_Rstudio['megf22.6']= psds_mean_chan[:,90]\n",
    "subject_df_Rstudio['megf30']= psds_mean_chan[:,95]\n",
    "subject_df_Rstudio['megf32']= psds_mean_chan[:,100]\n",
    "subject_df_Rstudio['megf36']= psds_mean_chan[:,103]\n",
    "subject_df_Rstudio['megf36.8']= psds_mean_chan[:,104]\n",
    "subject_df_Rstudio['megf38']= psds_mean_chan[:,105]\n",
    "\n",
    "subject_df_Rstudio.to_csv('./stats_model_data_average_PSD.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
