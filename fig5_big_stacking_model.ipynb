{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "\n",
    "from hidimstat import CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921ef25-e55f-459e-8f09-435515584f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all_keys = pd.read_csv('./features_all_keys.csv')\n",
    "features_all_keys = [k for k in features_all_keys['subject']]\n",
    "features_all_keys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_fname = './participants.tsv'\n",
    "subject_df = pd.read_csv(participants_fname, delimiter='\\t')\n",
    "subject_df['participant_id'] = subject_df['participant_id'].str.replace('sub-', '')\n",
    "subject_df = subject_df.set_index('participant_id') # creates index (supprime la colonne participant_id et la met en index)\n",
    "subject_df = subject_df.loc[features_all_keys] # dataframe in correct order (without the patient with no eeg)\n",
    "subject_df.head()\n",
    "subject_converter_df = subject_df.dropna(subset=['Converters']) # create new df use JUST for STATS \n",
    "subject_converter_df.head(140)\n",
    "feature_converter = subject_df['Converters'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd489f-b6c2-4682-8d2d-b5c04d758cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(subject_converter_df[['group', 'sex', 'site', 'Edu_years', 'MMSE']].isna().sum(axis=1)>=1)\n",
    "\n",
    "sum(subject_converter_df[['Edu_years']].isna().sum(axis=1)>=1)\n",
    "\n",
    "sum(subject_converter_df[['MMSE']].isna().sum(axis=1)>=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = feature_converter[feature_converter!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds_covs_df = pd.read_csv('./cv_preds_covs.csv')\n",
    "cv_preds_psd_df = pd.read_csv('./cv_preds_psd.csv').drop(labels=['fold_idx', 'repeat', 'sample_index'], axis=1)\n",
    "cv_preds_wpli_df = pd.read_csv('./cv_preds_wpli.csv').drop(labels=['fold_idx', 'repeat', 'sample_index'], axis=1)\n",
    "cv_preds_rplain_df = pd.read_csv('./cv_preds_rplain.csv').drop(labels=['fold_idx', 'repeat', 'sample_index'], axis=1)\n",
    "cv_preds_mri_df = pd.read_csv('./cv_preds_mri.csv').drop(labels=['fold_idx', 'repeat', 'sample_index'], axis=1)\n",
    "cv_preds_site_df = pd.read_csv('./cv_preds_site.csv').drop(labels=['fold_idx', 'repeat', 'sample_index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d289e-0ef9-4aa7-92bb-d74edcb8d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds_mri_df = pd.read_csv('./cv_preds_mri.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701d54e-2afb-4299-864b-78503a089a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds_mri_df.sample_index.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6db04-3add-4167-8796-0dc52bd86a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_converter_df.index[\n",
    "    np.unique(cv_preds_mri_df.sample_index[np.where(cv_preds_mri_df['mri'].isna())[0]])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160d377-a799-4995-a96e-b63ddaed762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds_mri_df = pd.read_csv('./cv_preds_mri.csv').drop(labels=['fold_idx', 'repeat', 'sample_index'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9dbe6d-88f8-4da8-8a03-bb9790f5b4ba",
   "metadata": {},
   "source": [
    "## Site Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbecfd2-f310-4733-b6f9-914f4ec1a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_site = subject_converter_df[['age', 'sex', 'Edu_years']]\n",
    "X_df_site['sex'] = X_df_site['sex'] == 'M' # tf the cat var into bool\n",
    "y_site = subject_converter_df['site'] == 'CBU'# tf site in bool\n",
    "X_df_site['Edu_years'] = X_df_site['Edu_years'].fillna(X_df_site['Edu_years'].mean()) # 10 missing data, input mean over all sub\n",
    "#X_df_site.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68d432-8fc5-42e5-a948-e047e4065469",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_converter_df['MMSE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c447c7-b3eb-46d2-a0ad-951323859d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(s):\n",
    "    return np.fromstring(s.strip('[]'), sep=' ', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b34b82-e976-4530-a8ab-e93e24ac3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10 # the number of CV splits\n",
    "n_repeat = 10 # the number of randomized repetitions to get a nicer distribution\n",
    "# Consider putting n_repeats to 1 for the beginning.\n",
    "df_cv_site = pd.concat([\n",
    "    pd.DataFrame(\n",
    "        list(StratifiedKFold(n_splits=n_splits, random_state=ii * 7, shuffle=True).split(X_df_site, y_site)),\n",
    "        columns=['train', 'test']).assign(rep=ii, fold_idx=range(n_splits)) for ii in range(n_repeat)]\n",
    ")    \n",
    "\n",
    "if True: # write/read test\n",
    "    df_cv_site.to_csv('df_cv_site.csv', index=False)\n",
    "    df_cv_site = pd.read_csv(\n",
    "        'df_cv_site.csv', dtype=[('train', np.ndarray), \n",
    "                            ('test', np.ndarray),\n",
    "                            ('rep', int),\n",
    "                            ('fold_idx', int)]\n",
    "    )\n",
    "    df_cv_site['train'] = df_cv_site['train'].apply(string_to_array)\n",
    "    df_cv_site['test'] = df_cv_site['test'].apply(string_to_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f6408-bed4-4777-b6fe-aebfd88b1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10 # the number of CV splits\n",
    "n_repeat = 10 # the number of randomized repetitions to get a nicer distribution\n",
    "# Consider putting n_repeats to 1 for the beginning.\n",
    "df_cv = pd.concat([\n",
    "    pd.DataFrame(\n",
    "        list(StratifiedKFold(n_splits=n_splits, random_state=ii * 7, shuffle=True).split(X_df_site, y)),\n",
    "        columns=['train', 'test']).assign(rep=ii, fold_idx=range(n_splits)) for ii in range(n_repeat)]\n",
    ")    \n",
    "\n",
    "if True: # write/read test\n",
    "    df_cv.to_csv('df_cv_cases.csv', index=False)\n",
    "    df_cv = pd.read_csv(\n",
    "        'df_cv_cases.csv', dtype=[('train', np.ndarray), \n",
    "                            ('test', np.ndarray),\n",
    "                            ('rep', int),\n",
    "                            ('fold_idx', int)]\n",
    "    )\n",
    "    df_cv['train'] = df_cv['train'].apply(string_to_array)\n",
    "    df_cv['test'] = df_cv['test'].apply(string_to_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912769c-e0a5-4583-809b-c1263eec92ca",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8affb-8a6b-4e58-b0ab-28ac51d9d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.iloc[-2, :].test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae69fa3-d47b-4bc9-aea0-e113b222c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds_covs_df['sample_index']\n",
    "# cv_preds_wpli_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bceb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stacked = pd.concat([cv_preds_covs_df, cv_preds_psd_df, cv_preds_wpli_df, cv_preds_rplain_df, cv_preds_mri_df, cv_preds_site_df]\n",
    ", axis=1, join='outer')[['fold_idx', 'repeat', 'sample_index', 'covs', 'psd', 'rplain', 'wpli', 'mri']]\n",
    "# X_stacked.to_csv('./output/X_stacked.csv')\n",
    "X_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = ['site', 'edu', 'age', 'sex', 'mmse']\n",
    "\n",
    "feat_combinations = {\n",
    "    'Site': ['site'],\n",
    "    'MMSE': ['mmse'],\n",
    "    'Age': ['age'],\n",
    "    'Sex': ['sex'],\n",
    "    'Covariance': ['covs'],\n",
    "    'Pow. Env.': ['rplain'],\n",
    "    'dwPLI': ['wpli'],\n",
    "    'MRI': ['mri'],\n",
    "    'Full Model': baseline + ['covs', 'rplain', 'wpli', 'mri']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad95715-8eea-402b-a8e9-085571149585",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_converter_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4894d-0f08-48be-b2bb-5ba891992f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_converter_df['Edu_years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047ce6f-f252-427b-844d-fded01e94f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8984e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = True\n",
    "pred_mode = 'refit'\n",
    "if recompute:\n",
    "    model_grid_search = make_pipeline(\n",
    "        IterativeImputer(),\n",
    "        StandardScaler(),\n",
    "        LogisticRegressionCV(Cs=np.logspace(-3, 5, 50), cv=10, scoring=\"neg_log_loss\")\n",
    "    )\n",
    "    # stacking with RF not fine tuned for all combinations\n",
    "    print('Recomputing stacking models ...')\n",
    "    results = list()\n",
    "    for name, features in feat_combinations.items():\n",
    "        for rep in range(10):\n",
    "                    \n",
    "            X_ = X_stacked.query(f'repeat=={rep}')\n",
    "            sample_idx = X_['sample_index'].values\n",
    "            X_['mmse'] = subject_converter_df['MMSE'].values[sample_idx]\n",
    "            X_['site'] = (subject_converter_df['site']\n",
    "                          .map({'CTB': 0, 'CBU': 1})\n",
    "                          .values[sample_idx])\n",
    "            X_['edu'] = subject_converter_df['Edu_years'].values[sample_idx]\n",
    "            X_['age'] = subject_converter_df['age'].values[sample_idx]\n",
    "            X_['sex'] = subject_converter_df['sex'].map({'M': 0, 'F': 1}).values[sample_idx]\n",
    "            if features in [['covs'], ['rplain'], ['wpli'], ['mri']] and pred_mode == 'raw':\n",
    "                splitter = LeaveOneGroupOut().split(\n",
    "                    X_[features], y.values[sample_idx], groups=X_['fold_idx']\n",
    "                )\n",
    "                res = list()\n",
    "                for train, test in splitter:\n",
    "                    auc = roc_auc_score(\n",
    "                        y_true= y.values[sample_idx][test], y_score=X_[features].values[test]\n",
    "                    )\n",
    "                    res.append(auc)\n",
    "\n",
    "            res = cross_val_score(\n",
    "                X=X_[features],\n",
    "                groups=X_['fold_idx'],\n",
    "                y=y.values[sample_idx],\n",
    "                estimator=model_grid_search,\n",
    "                scoring='roc_auc',\n",
    "                cv=LeaveOneGroupOut(),\n",
    "                n_jobs=4,\n",
    "            )\n",
    "            this_result = pd.DataFrame(dict(scores=res))\n",
    "            this_result['rep'] = rep\n",
    "            this_result['split'] = range(10)\n",
    "            this_result['variables'] = name\n",
    "            results.append(this_result)\n",
    "            print(f'{name} auc: {res.mean():.3f}+/-{res.std():.3f}')\n",
    "    results_df = pd.concat(results)\n",
    "    results_df.to_csv('./stacking_variables_scoring_linear.csv')\n",
    "else:\n",
    "    print('Loading precomputed data ...')\n",
    "\n",
    "results_df_linear = pd.read_csv('./stacking_variables_scoring_linear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44aec8f-245d-4a15-a550-8f3aabc13c15",
   "metadata": {},
   "source": [
    "# Some general plotting config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c486748-9162-4a92-9f0f-c3a315a57fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "\n",
    "from utils import CUSTOM_COLORS as colors\n",
    "from utils import compute_corrected_ttest\n",
    "\n",
    "plt.rc('font', family='sans-serif', )\n",
    "sns.set_context('paper', rc={\"lines.linewidth\": 2,})\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 13\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a90923-5690-4b7a-a384-31d66f9c68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(df, model_a, model_b):\n",
    "    \"\"\"\n",
    "    Computes split-wise differences between two models.\n",
    "    \n",
    "    Args:\n",
    "    df: DataFrame with 'scores', 'model', and 'split' columns.\n",
    "    model_a: Name of the first model.\n",
    "    model_b: Name of the second model.\n",
    "    \n",
    "    Returns:\n",
    "    A Series with the score differences for each split.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pivot the DataFrame to have models as columns and splits as rows\n",
    "    df_pivot = df.pivot(index='cv_idx', columns='variables', values='scores')\n",
    "    \n",
    "    # Calculate the difference between the two models\n",
    "    diff = df_pivot[model_a] - df_pivot[model_b] \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5304a48-06eb-458c-b51b-cbe8b1f7c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_corrected_ttest(differences, df):\n",
    "    \"\"\"Computes right-tailed paired t-test with corrected variance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : array-like of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    df : int\n",
    "        Degrees of freedom.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t_stat : float\n",
    "        Variance-corrected t-statistic.\n",
    "    p_val : float\n",
    "        Variance-corrected p-value.\n",
    "    \"\"\"\n",
    "    mean = np.mean(differences)\n",
    "    std = corrected_std(differences)\n",
    "    t_stat = mean / std\n",
    "    p_val = stats.t.sf(t_stat, df)  # right-tailed t-test\n",
    "    return t_stat, p_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e206858-d106-4d38-996a-72a42456bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrected_std(differences):\n",
    "    \"\"\"Corrects standard deviation using Nadeau and Bengio's approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : ndarray of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corrected_std : float\n",
    "        Variance-corrected standard deviation of the set of differences.\n",
    "    \"\"\"\n",
    "    # kr = k times r, r times repeated k-fold crossvalidation,\n",
    "    # kr equals the number of times the model was evaluated\n",
    "    kr = len(differences)\n",
    "    corrected_var = np.var(differences, ddof=1) * (1 / kr + 0.1 / 0.9)\n",
    "    corrected_std = np.sqrt(corrected_var)\n",
    "    return corrected_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deff4df-592e-44f5-a99b-426c1efa02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8f9fa-029f-45a7-832f-53801ff17e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['cv_idx'] = results_df.rep.astype(str) + results_df.split.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9435df-e656-4104-acfb-8c6ad2251673",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_lr_cv = make_pipeline(\n",
    "    IterativeImputer(),\n",
    "    StandardScaler(),\n",
    "    LogisticRegressionCV(Cs=np.logspace(-3, 5, 50), cv=10,\n",
    "                         scoring=\"neg_log_loss\")\n",
    ")\n",
    "imputation_rr_cv = make_pipeline(\n",
    "    IterativeImputer(),\n",
    "    StandardScaler(),\n",
    "    RidgeCV(alphas=np.logspace(-3, 5, 50))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60a950-6ee2-4f7e-8277-5712b0b918d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7fa680-c56d-444d-8fe0-064c56b906e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = baseline + ['wpli', 'rplain', 'covs', 'mri']\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb769d3-f5af-4351-a444-f8c85398d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cpi(rep, estimator, imputation_model, variables, impute=True):\n",
    "    X_sel = X_stacked.query(f'repeat=={rep}').reset_index()\n",
    "    groups = X_sel['fold_idx'].values\n",
    "    y_sel = y.values[X_sel['sample_index'].values]\n",
    "    assert np.unique(X_sel['sample_index'].values).shape[0] == len(y)\n",
    "    sample_idx = X_sel['sample_index'].values\n",
    "    if 'mmse' in variables:\n",
    "        mmse = subject_converter_df['MMSE'].values[sample_idx]\n",
    "        X_sel['mmse'] = mmse\n",
    "    if 'site' in variables:\n",
    "        X_sel['site'] = (\n",
    "            subject_converter_df['site']\n",
    "            .map({'CTB': 0, 'CBU': 1})\n",
    "            .values[sample_idx]\n",
    "        )\n",
    "    if 'edu' in variables: \n",
    "        X_sel['edu'] = subject_converter_df['Edu_years'].values[sample_idx]\n",
    "    if 'age' in variables:\n",
    "        X_sel['age'] = subject_converter_df['age'].values[sample_idx]\n",
    "    if 'sex' in variables:\n",
    "        X_sel['sex'] = subject_converter_df['sex'].map({'M': 0, 'F': 1}).values[sample_idx]\n",
    "    \n",
    "    X_sel = X_sel[variables]\n",
    "    logo = LeaveOneGroupOut()\n",
    "    logo_splits = list(logo.split(\n",
    "        X=X_sel, groups=groups\n",
    "    ))\n",
    "    loss_list_cv = list() \n",
    "\n",
    "    for ii, (train, test) in enumerate(logo_splits):\n",
    "\n",
    "        imputer = IterativeImputer()\n",
    "        if impute:\n",
    "            X_imp = imputer.fit_transform(X_sel.values[train])\n",
    "        else:\n",
    "            X_imp = X_sel.values[train]\n",
    "\n",
    "        estimator.fit(X_imp, y_sel[train])\n",
    "        \n",
    "        print(\n",
    "            roc_auc_score(\n",
    "                y_true=y_sel[test],\n",
    "                y_score=estimator.predict_proba(X_sel.values[test])[:, 1]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        cpi = CPI(\n",
    "            estimator=estimator,\n",
    "            method='predict_proba',\n",
    "            random_state=42,\n",
    "            n_permutations=500,\n",
    "            imputation_model=clone(imputation_model),\n",
    "            loss=log_loss\n",
    "        )\n",
    "    \n",
    "        cpi.fit(X_imp, y_sel[train])\n",
    "\n",
    "        if impute:\n",
    "            X_imp_test = imputer.transform(X_sel.values[test])\n",
    "        else:\n",
    "            X_sel.values[test]\n",
    "\n",
    "        loss_result = cpi.score(X_imp_test, y_sel[test])\n",
    "    \n",
    "        loss_result_df = pd.DataFrame(loss_result['importance']).T\n",
    "        loss_result_df['cv_fold'] = ii\n",
    "        loss_result_df['rep'] = rep\n",
    "        loss_list_cv.append(\n",
    "            loss_result_df\n",
    "        )\n",
    "    return loss_list_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441c0bd-d3de-4aa9-9094-b5e1df682351",
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute = True\n",
    "if recompute:\n",
    "    loss_list_cv_ = Parallel(n_jobs=1)(delayed(run_cpi)(\n",
    "        rep=ii,\n",
    "        estimator=estimator_lr_cv,\n",
    "        imputation_model=imputation_rr_cv,\n",
    "        variables=variables)\n",
    "        for ii in range(10)\n",
    "    )\n",
    "    loss_list_cv_lm = sum(loss_list_cv_, [])\n",
    "    loss_list_cv_lm_df = pd.concat([pd.DataFrame(x) for x in loss_list_cv_lm])\n",
    "    loss_list_cv_lm_df.columns = variables + ['cv_fold', 'rep']\n",
    "    loss_list_cv_lm_df.to_csv('cpi_linear_models.csv')\n",
    "else:\n",
    "    loss_list_cv_lm_df = pd.read_csv('cpi_linear_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba148f-9cfc-4cd9-a7c1-aa9b58cf759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_cv_lm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb7709-2c7e-408e-8382-00d2d7a552f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(results_df, loss_list_cv_df, variables):\n",
    "    \n",
    "    fig, axes = plt.subplot_mosaic(\n",
    "        [['A', 'B']],\n",
    "        figsize=( 8, 3.5), \n",
    "        width_ratios=[1, 1.25],\n",
    "        sharex=False,\n",
    "        sharey=False,\n",
    "        layout=\"constrained\"\n",
    "    )\n",
    "    \n",
    "    sorted_vars = results_df.groupby('variables')['scores'].median().sort_values(ascending = False).index\n",
    "    sorted_df = results_df.set_index('variables').loc[sorted_vars].reset_index()\n",
    "    \n",
    "    axes['A'].axvline(0.5, c='black', linestyle='--')\n",
    "    print(sorted_df.groupby('variables').scores.agg(['mean', 'std']).round(3))\n",
    " \n",
    "    sns.pointplot(\n",
    "        sorted_df,\n",
    "        x=\"scores\", \n",
    "        y=\"variables\",\n",
    "        palette='viridis',\n",
    "        hue='variables',\n",
    "        errorbar=('ci', 95), \n",
    "        estimator='median',\n",
    "        marker='o',\n",
    "        alpha=1,\n",
    "        linestyle='',\n",
    "        markersize=8,\n",
    "        markerfacecolor='white',\n",
    "        markeredgecolor=None,\n",
    "        capsize=.33,\n",
    "        linewidth=2,\n",
    "        ax=axes['A']\n",
    "    ) \n",
    "    axes['A'].set_ylabel('')\n",
    "    axes['A'].set_xlabel('AUC')\n",
    "    axes['A'].set_xlim(0.4, 1.0)\n",
    "    axes['A'].annotate('a', xy=(-0.35, 0.99), xycoords='axes fraction', fontsize=BIGGER_SIZE, fontweight='bold')\n",
    "    axes['A'].set_title('Marginal Models VS Full Model', fontsize=MEDIUM_SIZE, x=0.44)\n",
    "    \n",
    "    \n",
    "    stats_res = list()\n",
    "    for ii, column in enumerate(variables):\n",
    "        tstat, pval = compute_corrected_ttest(loss_list_cv_df[column], len(loss_list_cv_df)-1)\n",
    "        stats_res.append({'stat': tstat , 'pval': pval, 'variable': column})\n",
    "    stats_res = pd.DataFrame(stats_res)\n",
    "    stats_res['variable'] = stats_res['variable'].map({\n",
    "        'site': 'Site',\n",
    "        'covs': 'Cov.',\n",
    "        'wpli': 'dwPLI',\n",
    "        'rplain': 'P. Env.',\n",
    "        'mri': 'MRI',\n",
    "        'mmse': 'MMSE',\n",
    "        'age': 'Age',\n",
    "        'sex': 'Sex',\n",
    "        'edu': 'Edu.'\n",
    "    })\n",
    "    stats_res = stats_res.set_index('variable')\n",
    "    print(stats_res.round(3))\n",
    "\n",
    "    loss_long_df = pd.melt(loss_list_cv_df, id_vars=['rep', 'cv_fold'], value_vars=variables)\n",
    "    loss_long_df['variable'] = loss_long_df['variable'].map({\n",
    "        'site': 'Site',\n",
    "        'covs': 'Cov.',\n",
    "        'wpli': 'dwPLI',\n",
    "        'rplain': 'P. Env.',\n",
    "        'mri': 'MRI',\n",
    "        'mmse': 'MMSE',\n",
    "        'age': 'Age',\n",
    "        'sex': 'Sex',\n",
    "        'edu': 'Edu.'\n",
    "    })\n",
    "\n",
    "    loss_sorted = loss_long_df.groupby('variable')['value'].median().sort_values(ascending=False).index\n",
    "    \n",
    "    loss_long_df_sorted = loss_long_df.set_index('variable').loc[loss_sorted].reset_index()\n",
    "\n",
    "\n",
    "    axes['B'].axvline(0, c='black', linestyle='--')\n",
    "    \n",
    "    sns.pointplot(\n",
    "        loss_long_df_sorted,\n",
    "        x=\"value\", \n",
    "        y=\"variable\",\n",
    "        hue='variable',\n",
    "        palette='viridis',\n",
    "        errorbar=('ci', 95), \n",
    "        estimator='median',\n",
    "        marker='o',\n",
    "        alpha=1,\n",
    "        linestyle='',\n",
    "        markersize=8,\n",
    "        markerfacecolor='white',\n",
    "        markeredgecolor=None,\n",
    "        capsize=.33,\n",
    "        linewidth=2,\n",
    "        ax=axes['B']\n",
    "    ) \n",
    "    axes['B'].set_ylabel('')\n",
    "    axes['B'].set_xlabel(r'Importance ($\\Delta$ loss)')\n",
    "    axes['B'].set_xlim(-0.05, 0.1)\n",
    "    \n",
    "    axes['B'].annotate('b', xy=(-0.25, 0.99), xycoords='axes fraction', fontsize=BIGGER_SIZE, fontweight='bold')\n",
    "    axes['B'].set_title('Variable Importance (Full Model)', fontsize=MEDIUM_SIZE, x=0.34)\n",
    "    \n",
    "    annot_df = stats_res.loc[loss_sorted]\n",
    "    for ii, (name, row) in enumerate(annot_df.iterrows()):\n",
    "        pval = row.pval\n",
    "        label = r'$p=%0.3f$' % pval\n",
    "        if pval < 0.01 and row.stat > 0:\n",
    "            label += r'$^{\\ast\\ast}$'\n",
    "        elif pval < 0.05 and row.stat > 0:\n",
    "            label += r'$^{\\ast}$'\n",
    "        axes['B'].annotate(label, xy=(-0.04, ii + 0.14),\n",
    "                           color='purple' if pval < 0.05 and row.stat > 0 else 'black')\n",
    "\n",
    "    sns.despine(trim=True, offset=2)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1092377-2381-4bff-9a6d-159d7cd515c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = make_plot(results_df=results_df_linear, loss_list_cv_df=loss_list_cv_lm_df, variables=variables)\n",
    "for panel in ['A', 'B']: \n",
    "    axes[panel].set_yticklabels(\n",
    "        [r'MEG$_{(Cov.)}$' if (ll.get_text() == 'Cov.' or ll.get_text() == 'Covariance')\n",
    "         else ll for ll in axes[panel].get_yticklabels()]\n",
    "    )\n",
    "    axes[panel].set_yticklabels(\n",
    "        [r'MEG$_{(dwPLI.)}$' if ll.get_text() == 'dwPLI' else ll for ll in axes[panel].get_yticklabels()]\n",
    "    )\n",
    "    axes[panel].set_yticklabels(\n",
    "        [r'MEG$_{(P. Env.)}$' if (ll.get_text() == 'P. Env.' or ll.get_text() == 'Pow. Env.')\n",
    "         else ll for ll in axes[panel].get_yticklabels()]\n",
    "    )\n",
    "\n",
    "fig.savefig('linear_model_comp.png', dpi=300)\n",
    "fig.savefig('linear_model_comp.pdf', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meeg_analysis",
   "language": "python",
   "name": "meeg_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
